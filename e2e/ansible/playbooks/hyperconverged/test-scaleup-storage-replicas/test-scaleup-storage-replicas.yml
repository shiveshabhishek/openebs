# Description: Scaleup the storage replicas and test is there any impact on pods.
# Author: Swarna

########################################################################################
# Test Steps:
#1.Check the maya-apiserver is running.
#2.Download and Copy Test artifacts to kubemaster.
#3.Replace PVC name with test case name in percona yaml
#4.Get the Nodes count and modify the replica count in storage class.
#5.Delete the existing storage class and create new one.
#6.Deploy Percona application with liveness probe running db queries continuously
#7.Check percona and replica pods are running and store the replica pod names in a list
#8.Scaleup the storage replica count using kubectl command.
#9.Check the scaled up replica is running and store the replicas name in list.
#10.Check access mode of replica using mayactl command.
#11.Get the replica name which is scheduled before scaleup and kill that replica
#12.Check the application pod status and check replica is re-schduled again after deleting replica.
#14.Perform cleanup.
##########################################################################################

- hosts: localhost

  vars_files:
    - vars.yml

  tasks:

   - block:

       - include: pre-requisites.yml


       - name: Check status of apiserver
         include_tasks: "{{ansible_env.HOME}}/{{utils_path}}/deploy_check.yml"
         vars:
           ns: openebs
           app: apiserver

       - name: Get percona spec and liveness scripts
         get_url:
           url: "{{ item }}"
           dest: "{{ result_kube_home.stdout }}"
         delegate_to: "{{ groups['kubernetes-kubemasters'].0 }}"
         with_items: "{{ percona_links }}"

       - name: Replace volume-claim name with test parameters
         include_tasks: "{{ansible_env.HOME}}/{{utils_path}}/regex_task.yml"
         vars:
           path: "{{ result_kube_home.stdout }}/percona.yaml"
           regex1: "{{replace_item}}"
           regex2: "{{replace_with}}"
         delegate_to: "{{ groups['kubernetes-kubemasters'].0 }}"

       - name: Get the number of nodes in the cluster
         shell: source ~/.profile; kubectl get nodes | grep 'none' | wc -l
         args:
           executable: /bin/bash
         register: node_out
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Fetch the node count from stdout
         set_fact:
            node_count: " {{ node_out.stdout}}"

       - name: Obtaining storage classes yaml
         shell: source ~/.profile; kubectl get sc openebs-percona -o yaml > "{{ create_sc }}"
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Replace the replica count in openebs-storageclasses yaml
         replace:
           path: "{{ create_sc }}"
           regexp: 'openebs.io/jiva-replica-count: "3"'
           replace: 'openebs.io/jiva-replica-count: "{{ (node_count) |int-1 }}"'
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Delete the existing storage class and create new one
         shell: source ~/.profile; kubectl delete sc openebs-percona; kubectl apply -f "{{ create_sc }}"
         args:
           executable: /bin/bash
         register: sc_out
         until: "'created' in sc_out.stdout"
         delay: 10
         retries: 5
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"



       - name: Create namespace to deploy application
         shell: source ~/.profile; kubectl create ns {{ namespace }}
         args:
           executable: /bin/bash
         delegate_to: "{{ groups['kubernetes-kubemasters'].0 }}"

       - name: Create a configmap with the liveness sql script
         shell: source ~/.profile; kubectl create configmap sqltest --from-file={{ result_kube_home.stdout }}/{{ percona_files.1 }} -n {{ namespace }}
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: result
         failed_when: "'configmap' and 'created' not in result.stdout"

       - include_tasks: "{{ansible_env.HOME}}/{{utils_path}}/deploy_task.yml"
         vars:
           app_yml: "{{ percona_files.0 }}"
           ns: "{{ namespace }}"

       - include_tasks: "{{ansible_env.HOME}}/{{utils_path}}/deploy_check.yml"
         vars:
            ns: "{{ namespace }}"
            app: percona

       - name: Wait for 120s to ensure liveness check starts
         wait_for:
           timeout: 120

       - name: Get any one of the replica name
         shell: source ~/.profile; kubectl get pods -n {{ namespace }} | grep rep | awk {'print $1'} |  awk 'FNR == 1 {print}'
         args:
           executable: /bin/bash
         register: old_replica_name
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"


       - name: Get the replica deployment name
         shell: source ~/.profile; kubectl get deployment -n {{ namespace }} | grep rep | awk {'print $1'}
         args:
           executable: /bin/bash
         register: rep_deployment_name
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       #### scale up the stoarge replica using kubectl command ####

       - name: Scaleup the srorage replicas using kubectl command
         shell: source ~/.profile; kubectl scale deployment {{ rep_deployment_name.stdout }} --replicas={{(node_count |int)}} -n {{ namespace }}
         args:
           executable: /bin/bash
         result: result
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Confirm scaled up replica  pod status is running
         shell: source ~/.profile; kubectl get pods -n {{ namespace }} | grep rep | grep Running | wc -l
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: result
         until: (node_count)| int == result.stdout|int
         delay: 120
         retries: 30


       - name: Wait for 180s to ensure Replicas access mode
         wait_for:
           timeout: 180

        #### Check the replica access mode after scaling up using mayactl commands ####
       - name: Check the replicas access mode
         include_tasks: "{{ansible_env.HOME}}/{{utils_path}}/access-mode-check.yml"
         vars:
           ns: "{{ namespace }}"

        #### Delete the replica which is scheduled before scale up to check newly crated replica is in sync"

       - name: Delete the replica which is scheduled before scale up
         shell: source ~/.profile; kubectl delete pod {{ old_replica_name.stdout }} -n "{{ namespace }}"
         args:
           executable: /bin/bash
         register: pod_delete
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         until: "'deleted' in pod_delete.stdout"
         delay: 60
         retries: 3
         changed_when: True
         tags:
          - skip_ansible_lint

       - include_tasks: "{{ansible_env.HOME}}/{{utils_path}}/deploy_check.yml"
         vars:
            ns: "{{ namespace }}"
            app: percona

       - name: Confirm the replica is scheduled again
         shell: source ~/.profile; kubectl get pods -n {{ namespace }} | grep rep | grep Running | wc -l
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: result
         until: (node_count)| int == (result.stdout)|int
         delay: 120
         retries: 30


       - name: Test Passed
         set_fact:
           flag: "Test Passed"
           status_id: 1

       - name: Set Status
         set_fact:
           status: "good"

     rescue:
       - name: Test Failed
         set_fact:
           flag: "Test Failed"
           status_id: 5

       - name: Set Status
         set_fact:
           status: "danger"

     always:
       - block:

           - include: cleanup.yml

           - name: Test Cleanup Passed
             set_fact:
               cflag: "Cleanup Passed"

         rescue:
           - name: Test Cleanup Failed
             set_fact:
               cflag: "Cleanup Failed"

         always:

           - include_tasks: "{{ansible_env.HOME}}/{{utils_path}}/stern_task.yml"
             vars:
               status: stop

           - block:
               - name: Update Testrail
                 shell: source ~/.profile; python3 {{ inventory_dir | dirname }}/files/updater.py -tuser {{ testrail_user }} -tpass {{ testrail_password }} -sid {{ test_suite_id }} -cid {{ test_case_id }} -stid {{ status_id }}
                 args:
                   executable: /bin/bash

               - name: Testrail Updated
                 set_fact:
                   tflag: "Testrail Updated"

             rescue:
               - name: Testrail Update failed
                 set_fact:
                   tflag: "Testrail Update Failed"

           - name: Send slack notification
             slack:
               token: "{{ lookup('env','SLACK_TOKEN') }}"
               msg: '{{ ansible_date_time.time }} TEST: {{test_name}}, RESULT: {{ flag }},{{ cflag }},{{tflag}}'
               color: "{{status}}"
             when: slack_notify | bool and lookup('env','SLACK_TOKEN')








